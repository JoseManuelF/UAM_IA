{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Práctica 4 de IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Construcción de un clasificador en una base de datos real (1.5 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pima.csv\", header=0, sep=',')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El objetivo es predecir si una paciente tiene o no diabetes a partir de los valores de otras variables. La variable target es \"class\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Pregnancies:** Number of times pregnant\n",
    "* **Glucose:** Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "* **BloodPressure:** Diastolic blood pressure (mm Hg)\n",
    "* **SkinThickness:** Triceps skin fold thickness (mm)\n",
    "* **Insulin:** 2-Hour serum insulin (mu U/ml)\n",
    "* **BMI:** Body mass index (weight in kg/(height in m)^2)\n",
    "* **DiabetesPedigreeFunction:** Diabetes pedigree function\n",
    "* **Age:** Age (years)\n",
    "* **Class:** Class variable (\"yes\" / \"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_atrs = list(df.columns)\n",
    "nombres_atrs.remove('class')\n",
    "print(nombres_atrs)\n",
    "X = df[nombres_atrs].values\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estadísticos básicos de cada atributo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogramas suavizados de cada atributo en cada clase. El color indica la clase (\"yes\"/\"no\"):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "for i,n in enumerate(nombres_atrs):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    aux = 'Density' if i%4==0 else ''\n",
    "    df.groupby(\"class\")[n].plot(kind='kde', title='Hist. de '+n)\n",
    "    plt.ylabel(aux);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de un modelo y chequeo de su calidad usando 5-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda entrena un modelo y lo evalúa en varias particiones training-test diferentes de los datos. El resultado es un score medio junto a su desviación estándar. El tipo de modelo (Naïve Bayes / árbol de decisión / knn/ regresión logística / red neuronal) y parámetros empleados deberán ser seleccionados para que dicho resultado sea el mejor posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nn\n",
    "for i in range(1,11):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"k=\" + str(i) + \" Score global del modelo: {:.2f} +/- {:.2f}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "for i in range(1,11):\n",
    "    clf = DecisionTreeClassifier(max_depth=i)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"d=\" + str(i) + \" Score global del modelo: {:.2f} +/- {:.2f}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Responde aquí a las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Cuál es el mejor score que consigues con un k-nn y con qué k (valor de n_neighbours)?\n",
    "* ¿Cuál es el mejor score que consigues con un árbol de decisión y con qué profundidad máxima (valor de max_depth)?\n",
    "* ¿Cuál es el mejor score que consigues con una red neuronal y con qué configuración (valor de hidden_layer_sizes)?\n",
    "\n",
    "Nota: para responder a estas preguntas sólo hay que cambiar el tipo de modelo y sus parámetros en la celda anterior."
   ]
  },
  {
   "source": [
    "All the results to these questions have been deduced with the code provided above for each model type.\n",
    "\n",
    "* The best k for the k-nn algorithm is **k=8** with a global score of the model: 0.75 +/- 0.02\n",
    "\n",
    "* The best maximum depth for the decision tree is **d=5** with a global score of the model: 0.75 +/- 0.04"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python363jvsc74a57bd07624ca621d7ec95efb7e698cb955bbc1691c5a7ba16307613ed4f0fde6f6b148",
   "display_name": "Python 3.6.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "7624ca621d7ec95efb7e698cb955bbc1691c5a7ba16307613ed4f0fde6f6b148"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}